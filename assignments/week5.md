Week 5 Homework
--

Due Friday at 11:55pm.

A.  Note that "Explain" can be interpreted to mean "Explain as briefly as possible."  More text != a better answer.
   
   Pick **four** of the following seven questions to answer.

1.  T/F  Smaller hypothesis spaces tend to have higher Rademcher complexity than larger ones.  Explain.
    
2.  T/F  The VC-dimension is the maximum number of points that can be shattered in an infinite number of ways.  Explain.
    
3.  T/F  SVMs, logistic regression, and perceptrons are all examples of "families of functions."  Explain.


4.  T/F SVMs, Na√Øve Bayes, and logistic regression all find a hyperplane to separate data. Explain.

6.  What is a Rademacher variable, and what function does it serve in terms of determining Rademacher complexity?

7.  Which has higher entropy?  A rare word or a common word?  Explain.

B.  Using Vowpal Wabbit, using the data provided for Programming Assignemnt 2, run the experiment with at least two different
    loss functions (or neural networks or SVMs) and compare the results.  How does using L2 regularization affect the results?
    
C.  Go to https://www.kaggle.com/datasets and browse the data sets.  
    Describe at least two projects you would be interested in tackling and why.  (They need not be from Kaggle data sets.)
